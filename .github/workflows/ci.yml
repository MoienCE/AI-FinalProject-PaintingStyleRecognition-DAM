name: CI - EfficientNet Pipeline

on:
  push:
    branches: [ "phase-2", "main", "master" ]
  pull_request:
    branches: [ "phase-2", "main", "master" ]

jobs:
  ci:
    runs-on: ubuntu-latest
    
    env:
      WANDB_MODE: disabled

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install PyTorch (CPU)
        run: pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

      - name: Install dependencies
        run: |
          pip install pandas numpy pillow scikit-learn tqdm matplotlib seaborn wandb flask flask-cors tensorboard

      - name: Generate Dummy Data Script
        run: |
          cat <<EOF > create_dummy.py
          import pandas as pd, os
          from PIL import Image
          import numpy as np, json

          # Create directories
          os.makedirs("data/processed/splits", exist_ok=True)
          os.makedirs("data/processed/Style_A", exist_ok=True)
          os.makedirs("data/processed/Style_B", exist_ok=True)
          os.makedirs("models", exist_ok=True)
          os.makedirs("results/runs", exist_ok=True)

          paths = []
          labels = []

          # Generate 20 random images (384x384)
          for i in range(20):
              style = "Style_A" if i < 10 else "Style_B"
              label = 0 if i < 10 else 1
              img = Image.fromarray(np.random.randint(0, 255, (384, 384, 3), dtype=np.uint8))
              path = f"data/processed/{style}/dummy_{i}.jpg"
              img.save(path)
              paths.append(path)
              labels.append(label)

          # Create CSV splits
          df = pd.DataFrame({"image_path": paths, "label": labels})
          df.iloc[:12].to_csv("data/processed/splits/train.csv", index=False)
          df.iloc[12:16].to_csv("data/processed/splits/val.csv", index=False)
          df.iloc[16:].to_csv("data/processed/splits/test.csv", index=False)

          # Create mapping file
          with open("data/processed/splits/class_mapping.json", "w") as f:
              json.dump({"0": "Style_A", "1": "Style_B"}, f)

          print("✅ Dummy data (384x384) created successfully.")
          EOF

      - name: Run Dummy Data Generation
        run: python create_dummy.py

      # ── Smoke Training ──
      - name: Smoke Training (Fine-Tune B3)
        run: |
          python src/training/fine_tune.py \
            --model_type efficientnet_b3 \
            --epochs 1 \
            --batch_size 4 \
            --lr 1e-4 \
            --num_workers 0 \
            --exp_name ci_smoke_test

      # ── Evaluation ──
      - name: Run Evaluation
        run: |
          python src/evaluation/evaluate.py \
            --model_type efficientnet_b3 \
            --batch_size 4

      # ── API Test ──
      - name: Smoke Test API Code
        run: |
          python -c "from src.models.models import get_model; print('API Model Import OK')"

      # ── Artifacts ──
      - name: Upload evaluation report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-results
          path: results/
          retention-days: 7